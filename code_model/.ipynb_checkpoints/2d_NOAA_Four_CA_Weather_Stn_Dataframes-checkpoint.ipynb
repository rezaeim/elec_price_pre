{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">  \n",
    "\n",
    "<b> <font size='5'>  \n",
    "ELEC PRICE PREDICTION CAPSTONE:</font>  \n",
    "\n",
    "<font size='4'>NOAA CA Weather DataFrame Creation Notebook</font> </b>\n",
    "\n",
    "<font size='3'>  \n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Manu Kalia Project Submission<br>\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; DSI-7-SF<br>\n",
    "&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 15-May-2019<br>\n",
    "</font>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Declare-Variables,-Directories,-and-Column-Names\" data-toc-modified-id=\"Declare-Variables,-Directories,-and-Column-Names-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Declare Variables, Directories, and Column Names</a></span></li><li><span><a href=\"#Define-Functions\" data-toc-modified-id=\"Define-Functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Define Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Function-to-create-NOAA-weather-station-DataFrame\" data-toc-modified-id=\"Function-to-create-NOAA-weather-station-DataFrame-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Function to create NOAA weather station DataFrame</a></span></li><li><span><a href=\"#Function-to-extract-relevant-statistics-from-NOAA-column\" data-toc-modified-id=\"Function-to-extract-relevant-statistics-from-NOAA-column-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Function to extract relevant statistics from NOAA column</a></span></li><li><span><a href=\"#Function-to-print-relevant-descriptive-info-on-dataframe\" data-toc-modified-id=\"Function-to-print-relevant-descriptive-info-on-dataframe-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Function to print relevant descriptive info on dataframe</a></span></li><li><span><a href=\"#Function-to-replace--hard-coded-&quot;99xxx9&quot;-values-w/-NaNs\" data-toc-modified-id=\"Function-to-replace--hard-coded-&quot;99xxx9&quot;-values-w/-NaNs-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Function to replace  hard-coded \"99xxx9\" values w/ NaNs</a></span></li></ul></li><li><span><a href=\"#Read-in-Data-and-Create-4-Weather-Station-DataFrames\" data-toc-modified-id=\"Read-in-Data-and-Create-4-Weather-Station-DataFrames-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Read in Data and Create 4 Weather Station DataFrames</a></span></li><li><span><a href=\"#San-Diego-DataFrame\" data-toc-modified-id=\"San-Diego-DataFrame-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>San Diego DataFrame</a></span></li><li><span><a href=\"#Riverside-DataFrame\" data-toc-modified-id=\"Riverside-DataFrame-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Riverside DataFrame</a></span></li><li><span><a href=\"#Redding-DataFrame\" data-toc-modified-id=\"Redding-DataFrame-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Redding DataFrame</a></span></li><li><span><a href=\"#Fresno-DataFrame\" data-toc-modified-id=\"Fresno-DataFrame-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Fresno DataFrame</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import wget, os\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Declare Variables, Directories, and Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOAA Weather Station IDs:   ['72290023188', '72286903171', '72592024257', '72389093193']\n",
      "NOAA Weather Station Names: ['sand', 'rive', 'redd', 'fres']\n"
     ]
    }
   ],
   "source": [
    "stations_dict = {'72290023188': 'sand',        # San Diego\n",
    "                 '72286903171': 'rive',        # Riverside\n",
    "                 '72592024257': 'redd',        # Redding\n",
    "                 '72389093193': 'fres'         # Fresno\n",
    "                }\n",
    "\n",
    "stn_id_list   = list(stations_dict.keys())\n",
    "stn_name_list = list(stations_dict.values())\n",
    "\n",
    "print(f'NOAA Weather Station IDs:   {stn_id_list}')\n",
    "print(f'NOAA Weather Station Names: {stn_name_list}')\n",
    "\n",
    "# Dataframe names\n",
    "sand_df = None\n",
    "rive_df = None\n",
    "redd_df = None\n",
    "fres_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dirs = ['../raw_data/noaa_weather/2016/',\n",
    "                 '../raw_data/noaa_weather/2017/',\n",
    "                 '../raw_data/noaa_weather/2018/',\n",
    "                 '../raw_data/noaa_weather/2019/'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_orig_cols=['STATION',\n",
    "                   'DATE',\n",
    "                   'TMP',\n",
    "                   'WND',\n",
    "                   'CIG',\n",
    "                   'VIS']\n",
    "\n",
    "weather_new_cols =['stn_id',\n",
    "                   'datetime',\n",
    "                   'temp',\n",
    "                   'wind',\n",
    "                   'ceil',\n",
    "                   'vis']\n",
    "\n",
    "weather_rename_dict = {old: new for old, new in zip(weather_orig_cols,\n",
    "                                                    weather_new_cols)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Define Functions  \n",
    "\n",
    "### Function to create NOAA weather station DataFrame\n",
    "\n",
    "Parameters:  dataframe (df), index slice position in `stations_list`  \n",
    "\n",
    "Function steps:  \n",
    " 1. Instantiate DataFrame\n",
    " 2. Loop through the 4 annual download directories\n",
    " 3. Reading in data from .csv files, appending rows to new dataframe\n",
    " 3. Sort by `datetime` column, cast to 'datetime' object, and set as index \n",
    " 4. Sort by new `datetime` index to show rows in chronological order\n",
    " \n",
    " \n",
    "### Function to extract relevant statistics from NOAA column\n",
    "\n",
    "Parameters:  dataframe (df), orig_col_name (string), new_col_name (string), slice_index  \n",
    "\n",
    "Function steps:  \n",
    " 1. Step through rows of a dataframe\n",
    " 2. Extract a single statistic from a \"cell\" that is a tuple of strings\n",
    " 3. Store that stat in a new column whose name is a parameter\n",
    " 4. Drop the original data column from the dataframe\n",
    " \n",
    " \n",
    "### Function to print relevant descriptive info on dataframe\n",
    "\n",
    "Parameter:  dataframe (df)\n",
    "\n",
    "Function steps:\n",
    " 1. print df.shape\n",
    " 2. print null counts\n",
    " 3. print head(5)\n",
    " \n",
    " \n",
    " ### Function to replace  hard-coded \"99xxx9\" values w/ NaNs\n",
    "\n",
    "Parameter:  dataframe (df)\n",
    "\n",
    "Function steps:\n",
    " 1. replace specific codes (depends on which column) NOAA uses as NaN\n",
    " 2. return null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stn_df(df, stn_idx):\n",
    "    df       = pd.DataFrame(columns=weather_new_cols)\n",
    "    stn_name = list(stations_dict.values())[stn_idx]\n",
    "    stn_id   = list(stations_dict.keys())[stn_idx]\n",
    "\n",
    "    for directory in download_dirs:\n",
    "        file = directory + stn_id + '.csv'\n",
    "        temp_df = pd.read_csv(file,\n",
    "                              usecols=weather_orig_cols).rename(index=str,\n",
    "                                                                columns=weather_rename_dict)\n",
    "        df = df.append(temp_df, ignore_index=True, sort=True)\n",
    "\n",
    "    df = df.sort_values(by='datetime').reset_index(drop=True)\n",
    "\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    print(f'{stn_name}_df DataFrame Created')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statistic(df, orig_col_name, new_col_name, slice_index):\n",
    "    for row in range(0, df.shape[0]):\n",
    "        try:\n",
    "            statistic = df.loc[df.index[row], orig_col_name].split(',')[slice_index]\n",
    "            df.loc[df.index[row], new_col_name] = statistic\n",
    "            \n",
    "        except IndexError: break\n",
    "        except:\n",
    "            df.drop(labels=df.index[row], axis=0, inplace=True)  \n",
    "\n",
    "    df.drop(columns=[orig_col_name], inplace=True)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(df):\n",
    "    print(f'\\nShape: {df.shape}')\n",
    "    print(f'\\n  Nulls:\\n{df.isna().sum()}')\n",
    "    print(f'\\ndf.head()\\n{df.head()}')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nines(df):\n",
    "    df.replace('9999', np.nan, inplace=True)\n",
    "    df.replace('99999', np.nan, inplace=True)\n",
    "    df.replace('999999', np.nan, inplace=True)\n",
    "    df.isna().sum()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Read in Data and Create 4 Weather Station DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sand', 'rive', 'redd', 'fres']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stn_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../raw_data/noaa_weather/2016/72290023188.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zc/lhpyx9cd2pdg5g1k0srmc8880000gp/T/ipykernel_21478/940876108.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msand_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_stn_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msand_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrive_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_stn_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrive_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mredd_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_stn_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mredd_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfres_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_stn_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfres_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/zc/lhpyx9cd2pdg5g1k0srmc8880000gp/T/ipykernel_21478/2611580001.py\u001b[0m in \u001b[0;36mcreate_stn_df\u001b[0;34m(df, stn_idx)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdownload_dirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstn_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         temp_df = pd.read_csv(file,\n\u001b[0m\u001b[1;32m      9\u001b[0m                               \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweather_orig_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                                 columns=weather_rename_dict)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../raw_data/noaa_weather/2016/72290023188.csv'"
     ]
    }
   ],
   "source": [
    "sand_df = create_stn_df(sand_df, 0)\n",
    "rive_df = create_stn_df(rive_df, 1)\n",
    "redd_df = create_stn_df(redd_df, 2)\n",
    "fres_df = create_stn_df(fres_df, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## San Diego DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zc/lhpyx9cd2pdg5g1k0srmc8880000gp/T/ipykernel_21478/2897409896.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msand_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/zc/lhpyx9cd2pdg5g1k0srmc8880000gp/T/ipykernel_21478/2554350774.py\u001b[0m in \u001b[0;36msummarize\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nShape: {df.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n  Nulls:\\n{df.isna().sum()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\ndf.head()\\n{df.head()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "summarize(sand_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'drop_duplicates'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zc/lhpyx9cd2pdg5g1k0srmc8880000gp/T/ipykernel_21478/602178294.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msand_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'drop_duplicates'"
     ]
    }
   ],
   "source": [
    "sand_df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26409, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sand_df = sand_df.drop_duplicates()\n",
    "sand_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_statistic(sand_df, 'temp', 'sand_temp', 0)\n",
    "extract_statistic(sand_df, 'wind', 'sand_wind', 3)\n",
    "extract_statistic(sand_df, 'vis',  'sand_vis',  0)\n",
    "extract_statistic(sand_df, 'ceil', 'sand_ceil', 0)\n",
    "\n",
    "sand_df.drop(columns=['stn_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (26397, 4)\n",
      "\n",
      "  Nulls:\n",
      "sand_temp    6\n",
      "sand_wind    0\n",
      "sand_vis     0\n",
      "sand_ceil    0\n",
      "dtype: int64\n",
      "\n",
      "df.head()\n",
      "                    sand_temp sand_wind sand_vis sand_ceil\n",
      "datetime                                                  \n",
      "2016-01-01 00:00:00     +0161      0031   016000     99999\n",
      "2016-01-01 00:51:00     +0156      0026   016093     22000\n",
      "2016-01-01 01:51:00     +0144      0021   016093     22000\n",
      "2016-01-01 02:51:00     +0139      0000   016093     22000\n",
      "2016-01-01 03:51:00     +0133      0000   016093     22000\n"
     ]
    }
   ],
   "source": [
    "summarize(sand_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sand_temp       0\n",
       "sand_wind       9\n",
       "sand_vis        4\n",
       "sand_ceil    2379\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sand_df.dropna(inplace=True)\n",
    "replace_nines(sand_df)\n",
    "sand_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decided not to fill, because they are at \"odd\" times\n",
    "# that don't align with other measurent times (:51 past each hour)\n",
    "\n",
    "# sand_df.sand_ceil.fillna(method='ffill', inplace=True)\n",
    "# sand_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sand_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (24007, 4)\n",
      "\n",
      "  Nulls:\n",
      "sand_temp    0\n",
      "sand_wind    0\n",
      "sand_vis     0\n",
      "sand_ceil    0\n",
      "dtype: int64\n",
      "\n",
      "df.head()\n",
      "                    sand_temp sand_wind sand_vis sand_ceil\n",
      "datetime                                                  \n",
      "2016-01-01 00:51:00     +0156      0026   016093     22000\n",
      "2016-01-01 01:51:00     +0144      0021   016093     22000\n",
      "2016-01-01 02:51:00     +0139      0000   016093     22000\n",
      "2016-01-01 03:51:00     +0133      0000   016093     22000\n",
      "2016-01-01 04:51:00     +0122      0000   016093     22000\n"
     ]
    }
   ],
   "source": [
    "summarize(sand_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sand_df.to_csv('../data/san_diego_weather2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Riverside DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (33905, 5)\n",
      "\n",
      "  Nulls:\n",
      "ceil      0\n",
      "stn_id    0\n",
      "temp      0\n",
      "vis       0\n",
      "wind      0\n",
      "dtype: int64\n",
      "\n",
      "df.head()\n",
      "                            ceil       stn_id     temp           vis  \\\n",
      "datetime                                                               \n",
      "2016-01-01 00:53:00  22000,5,9,N  72286903171  +0133,5  016093,5,N,5   \n",
      "2016-01-01 01:53:00  22000,5,9,N  72286903171  +0128,5  016093,5,N,5   \n",
      "2016-01-01 02:53:00  22000,5,9,N  72286903171  +0122,5  016093,5,N,5   \n",
      "2016-01-01 03:53:00  22000,5,9,N  72286903171  +0117,5  016093,5,N,5   \n",
      "2016-01-01 04:53:00  22000,5,9,N  72286903171  +0111,5  016093,5,N,5   \n",
      "\n",
      "                               wind  \n",
      "datetime                             \n",
      "2016-01-01 00:53:00  030,5,N,0051,5  \n",
      "2016-01-01 01:53:00  040,5,N,0046,5  \n",
      "2016-01-01 02:53:00  040,5,N,0046,5  \n",
      "2016-01-01 03:53:00  060,5,N,0041,5  \n",
      "2016-01-01 04:53:00  040,5,N,0051,5  \n"
     ]
    }
   ],
   "source": [
    "summarize(rive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17294, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rive_df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17294, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rive_df = rive_df.drop_duplicates()\n",
    "rive_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_statistic(rive_df, 'temp', 'rive_temp', 0)\n",
    "extract_statistic(rive_df, 'wind', 'rive_wind', 3)\n",
    "extract_statistic(rive_df, 'vis',  'rive_vis',  0)\n",
    "extract_statistic(rive_df, 'ceil', 'rive_ceil', 0)\n",
    "\n",
    "rive_df.drop(columns=['stn_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (17294, 4)\n",
      "\n",
      "  Nulls:\n",
      "rive_temp    0\n",
      "rive_wind    0\n",
      "rive_vis     0\n",
      "rive_ceil    0\n",
      "dtype: int64\n",
      "\n",
      "df.head()\n",
      "                    rive_temp rive_wind rive_vis rive_ceil\n",
      "datetime                                                  \n",
      "2016-01-01 00:53:00     +0133      0051   016093     22000\n",
      "2016-01-01 01:53:00     +0128      0046   016093     22000\n",
      "2016-01-01 02:53:00     +0122      0046   016093     22000\n",
      "2016-01-01 03:53:00     +0117      0041   016093     22000\n",
      "2016-01-01 04:53:00     +0111      0051   016093     22000\n"
     ]
    }
   ],
   "source": [
    "summarize(rive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rive_temp      0\n",
       "rive_wind    111\n",
       "rive_vis      33\n",
       "rive_ceil     51\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rive_df.dropna(inplace=True)\n",
    "replace_nines(rive_df)\n",
    "rive_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# did not fill forward... small num of nulls\n",
    "\n",
    "# rive_df.sand_COLUMN.fillna(method='ffill', inplace=True)\n",
    "# rive_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rive_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (17142, 4)\n",
      "\n",
      "  Nulls:\n",
      "rive_temp    0\n",
      "rive_wind    0\n",
      "rive_vis     0\n",
      "rive_ceil    0\n",
      "dtype: int64\n",
      "\n",
      "df.head()\n",
      "                    rive_temp rive_wind rive_vis rive_ceil\n",
      "datetime                                                  \n",
      "2016-01-01 00:53:00     +0133      0051   016093     22000\n",
      "2016-01-01 01:53:00     +0128      0046   016093     22000\n",
      "2016-01-01 02:53:00     +0122      0046   016093     22000\n",
      "2016-01-01 03:53:00     +0117      0041   016093     22000\n",
      "2016-01-01 04:53:00     +0111      0051   016093     22000\n"
     ]
    }
   ],
   "source": [
    "summarize(rive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rive_df.to_csv('../data/riverside_weather2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redding DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (41245, 5)\n",
      "\n",
      "  Nulls:\n",
      "ceil      0\n",
      "stn_id    0\n",
      "temp      0\n",
      "vis       0\n",
      "wind      0\n",
      "dtype: int64\n",
      "\n",
      "df.head()\n",
      "                            ceil       stn_id     temp           vis  \\\n",
      "datetime                                                               \n",
      "2016-01-01 00:00:00  99999,9,9,N  72592024257  +0111,1  016000,1,9,9   \n",
      "2016-01-01 00:53:00  22000,5,9,N  72592024257  +0094,5  016093,5,N,5   \n",
      "2016-01-01 01:53:00  22000,5,9,N  72592024257  +0083,5  016093,5,N,5   \n",
      "2016-01-01 02:53:00  22000,5,9,N  72592024257  +0078,5  016093,5,N,5   \n",
      "2016-01-01 03:53:00  22000,5,9,N  72592024257  +0067,5  016093,5,N,5   \n",
      "\n",
      "                               wind  \n",
      "datetime                             \n",
      "2016-01-01 00:00:00  010,1,N,0088,1  \n",
      "2016-01-01 00:53:00  360,5,N,0072,5  \n",
      "2016-01-01 01:53:00  010,5,N,0093,5  \n",
      "2016-01-01 02:53:00  360,5,N,0067,5  \n",
      "2016-01-01 03:53:00  360,5,N,0072,5  \n"
     ]
    }
   ],
   "source": [
    "summarize(redd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25646, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redd_df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25646, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redd_df = redd_df.drop_duplicates()\n",
    "redd_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_statistic(redd_df, 'temp', 'redd_temp', 0)\n",
    "extract_statistic(redd_df, 'wind', 'redd_wind', 3)\n",
    "extract_statistic(redd_df, 'vis',  'redd_vis',  0)\n",
    "extract_statistic(redd_df, 'ceil', 'redd_ceil', 0)\n",
    "\n",
    "redd_df.drop(columns=['stn_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (25582, 4)\n",
      "\n",
      "  Nulls:\n",
      "redd_temp    32\n",
      "redd_wind     0\n",
      "redd_vis      0\n",
      "redd_ceil     0\n",
      "dtype: int64\n",
      "\n",
      "df.head()\n",
      "                    redd_temp redd_wind redd_vis redd_ceil\n",
      "datetime                                                  \n",
      "2016-01-01 00:00:00     +0111      0088   016000     99999\n",
      "2016-01-01 00:53:00     +0094      0072   016093     22000\n",
      "2016-01-01 01:53:00     +0083      0093   016093     22000\n",
      "2016-01-01 02:53:00     +0078      0067   016093     22000\n",
      "2016-01-01 03:53:00     +0067      0072   016093     22000\n"
     ]
    }
   ],
   "source": [
    "summarize(redd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "redd_temp       0\n",
       "redd_wind     194\n",
       "redd_vis       18\n",
       "redd_ceil    3170\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redd_df.dropna(inplace=True)\n",
    "replace_nines(redd_df)\n",
    "redd_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decided not to fill, because they are at \"odd\" times\n",
    "# that don't align with other measurent times (:53 past each hour)\n",
    "\n",
    "# redd_df.sand_ceil.fillna(method='ffill', inplace=True)\n",
    "# redd_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "redd_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (22201, 4)\n",
      "\n",
      "  Nulls:\n",
      "redd_temp    0\n",
      "redd_wind    0\n",
      "redd_vis     0\n",
      "redd_ceil    0\n",
      "dtype: int64\n",
      "\n",
      "df.head()\n",
      "                    redd_temp redd_wind redd_vis redd_ceil\n",
      "datetime                                                  \n",
      "2016-01-01 00:53:00     +0094      0072   016093     22000\n",
      "2016-01-01 01:53:00     +0083      0093   016093     22000\n",
      "2016-01-01 02:53:00     +0078      0067   016093     22000\n",
      "2016-01-01 03:53:00     +0067      0072   016093     22000\n",
      "2016-01-01 05:53:00     +0056      0072   016093     22000\n"
     ]
    }
   ],
   "source": [
    "summarize(redd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "redd_df.to_csv('../data/redding_weather2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fresno DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (37439, 5)\n",
      "\n",
      "  Nulls:\n",
      "ceil      0\n",
      "stn_id    0\n",
      "temp      0\n",
      "vis       0\n",
      "wind      0\n",
      "dtype: int64\n",
      "\n",
      "df.head()\n",
      "                            ceil       stn_id     temp           vis  \\\n",
      "datetime                                                               \n",
      "2016-01-01 00:00:00  99999,9,9,N  72389093193  +0106,1  011000,1,9,9   \n",
      "2016-01-01 00:53:00  22000,5,9,N  72389093193  +0100,5  011265,5,N,5   \n",
      "2016-01-01 01:53:00  22000,5,9,N  72389093193  +0078,5  011265,5,N,5   \n",
      "2016-01-01 02:53:00  22000,5,9,N  72389093193  +0067,5  009656,5,N,5   \n",
      "2016-01-01 03:53:00  22000,5,9,N  72389093193  +0056,5  008047,5,N,5   \n",
      "\n",
      "                               wind  \n",
      "datetime                             \n",
      "2016-01-01 00:00:00  290,1,N,0015,1  \n",
      "2016-01-01 00:53:00  999,9,C,0000,5  \n",
      "2016-01-01 01:53:00  999,9,C,0000,5  \n",
      "2016-01-01 02:53:00  999,9,C,0000,5  \n",
      "2016-01-01 03:53:00  310,5,N,0015,5  \n"
     ]
    }
   ],
   "source": [
    "summarize(fres_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24710, 5)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fres_df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24710, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fres_df = fres_df.drop_duplicates()\n",
    "fres_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_statistic(fres_df, 'temp', 'fres_temp', 0)\n",
    "extract_statistic(fres_df, 'wind', 'fres_wind', 3)\n",
    "extract_statistic(fres_df, 'vis',  'fres_vis',  0)\n",
    "extract_statistic(fres_df, 'ceil', 'fres_ceil', 0)\n",
    "\n",
    "fres_df.drop(columns=['stn_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (24676, 4)\n",
      "\n",
      "  Nulls:\n",
      "fres_temp    17\n",
      "fres_wind     0\n",
      "fres_vis      0\n",
      "fres_ceil     0\n",
      "dtype: int64\n",
      "\n",
      "df.head()\n",
      "                    fres_temp fres_wind fres_vis fres_ceil\n",
      "datetime                                                  \n",
      "2016-01-01 00:00:00     +0106      0015   011000     99999\n",
      "2016-01-01 00:53:00     +0100      0000   011265     22000\n",
      "2016-01-01 01:53:00     +0078      0000   011265     22000\n",
      "2016-01-01 02:53:00     +0067      0000   009656     22000\n",
      "2016-01-01 03:53:00     +0056      0015   008047     22000\n"
     ]
    }
   ],
   "source": [
    "summarize(fres_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fres_temp       0\n",
       "fres_wind      22\n",
       "fres_vis        5\n",
       "fres_ceil    2927\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fres_df.dropna(inplace=True)\n",
    "replace_nines(fres_df)\n",
    "fres_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decided not to fill, because they are at \"odd\" times\n",
    "# that don't align with other measurent times (:53 past each hour)\n",
    "\n",
    "# fres_df.sand_COLUMN.fillna(method='ffill', inplace=True)\n",
    "# fres_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fres_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape: (21711, 4)\n",
      "\n",
      "  Nulls:\n",
      "fres_temp    0\n",
      "fres_wind    0\n",
      "fres_vis     0\n",
      "fres_ceil    0\n",
      "dtype: int64\n",
      "\n",
      "df.head()\n",
      "                    fres_temp fres_wind fres_vis fres_ceil\n",
      "datetime                                                  \n",
      "2016-01-01 00:53:00     +0100      0000   011265     22000\n",
      "2016-01-01 01:53:00     +0078      0000   011265     22000\n",
      "2016-01-01 02:53:00     +0067      0000   009656     22000\n",
      "2016-01-01 03:53:00     +0056      0015   008047     22000\n",
      "2016-01-01 04:53:00     +0039      0000   006437     22000\n"
     ]
    }
   ],
   "source": [
    "summarize(fres_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fres_df.to_csv('../data/fresno_weather2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.641px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
