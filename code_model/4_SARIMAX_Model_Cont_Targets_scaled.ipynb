{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import wget, os\n",
    "import time\n",
    "import glob\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Matt Brems lecture\n",
    "\n",
    "def MSE(true, predicted):\n",
    "    squared_diff = np.square(true - predicted)\n",
    "    return np.mean(squared_diff)\n",
    "\n",
    "# Root Mean Square Error\n",
    "def RMSE(true, predicted):\n",
    "    squared_diff = np.square(true - predicted)    \n",
    "    return np.sqrt(np.mean(squared_diff))\n",
    "\n",
    "# R-squared, coefficient of determination\n",
    "def R_squared(true, predicted):\n",
    "    true      = np.array(true)\n",
    "    predicted = np.array(predicted)\n",
    "    sum_squared_diff = sum(np.square(true - predicted))\n",
    "    variance  = sum(np.square(true - np.mean(true)))\n",
    "    calc_r2   = 1 - (sum_squared_diff / variance)\n",
    "    return calc_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "---\n",
    "\n",
    "## Load Pickles:  Train/Test Dataframes &  Scaled Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/train_sc_df.pkl', 'rb') as f:\n",
    "    train_sc_df = pickle.load(f)\n",
    "    \n",
    "with open('../data/processed/test_sc_df.pkl', 'rb') as f:\n",
    "    test_sc_df = pickle.load(f)\n",
    "        \n",
    "with open('../data/pre_processed_df.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "with open('../data/processed/train.pkl', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "        \n",
    "with open('../data/processed/test.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_col_for_dam = [train.columns[i] for i, col in enumerate(df.columns) if col != 'dam_price_per_mwh']\n",
    "exog_col_for_hasp = [train.columns[i] for i, col in enumerate(df.columns) if col != 'hasp_price_per_mwh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc_dam = train_sc_df[exog_col_for_dam]\n",
    "X_test_sc_dam  = test_sc_df[exog_col_for_dam]\n",
    "y_train_dam    = train['dam_price_per_mwh']\n",
    "y_test_dam     = test['dam_price_per_mwh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc_hasp = train_sc_df[exog_col_for_hasp]\n",
    "X_test_sc_hasp  = test_sc_df[exog_col_for_hasp]\n",
    "y_train_hasp    = train['hasp_price_per_mwh']\n",
    "y_test_hasp     = test['hasp_price_per_mwh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21800,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_dam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21800, 27)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc_dam.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Gridsearch to find best MSE params for `P`, `D`, `Q`, and `S`\n",
    "\n",
    "(for `DAM` and `HASP` prices as endogenous variables,  \n",
    " use the ARIMA parameters for `p`, `d`, & `q` found in previous ARIMA gridsearch...  \n",
    " `DAM: 4, 0, 6`  and  `HASP: 6, 0 ,6`)\n",
    "\n",
    "> NOTE: Because of the amount of time each SARIMAX model takes to fit, there was simply not enough time to do these grid searches, although the code is correct and ready to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Matt Brem's grid search loop\n",
    "# Starting MSE and (P, D, Q).\n",
    "\n",
    "# mse = 99 * (10 ** 16)\n",
    "# final_P = 0\n",
    "# final_D = 0\n",
    "# final_Q = 0\n",
    "# final_S = 0\n",
    "\n",
    "# for P in range(3):\n",
    "#     for Q in range(3):\n",
    "#         for D in range(3):\n",
    "#             for S in range(0,24,8):\n",
    "#                 try:\n",
    "#                     # Instantiate SARIMA model.\n",
    "#                     sarima = SARIMAX(endog = y_train_dam,\n",
    "#                                      order = (4, 0, 6),              # (p, d, q)\n",
    "#                                      seasonal_order = (P, D, Q, S),  # (P, D, Q, S)\n",
    "#                                      exog = X_train_sc_dam) \n",
    "\n",
    "#                     # Fit SARIMA model.\n",
    "#                     model = sarima.fit()\n",
    "\n",
    "#                     # Generate predictions based on training set.\n",
    "#                     preds = model.predict()\n",
    "\n",
    "#                     # Evaluate predictions.\n",
    "#                     print(f'MSE for (4,0,6) x ({P},{D},{Q},{S}) ... {mean_squared_error(train[\"dam_price_per_mwh\"], preds)}')\n",
    "\n",
    "#                     # Save for final report.\n",
    "#                     if mse > mean_squared_error(train['dam_price_per_mwh'], preds):\n",
    "#                         mse = mean_squared_error(train['dam_price_per_mwh'], preds)\n",
    "#                         final_P = P\n",
    "#                         final_D = D\n",
    "#                         final_Q = Q\n",
    "#                         final_S = S\n",
    "\n",
    "#                 except:\n",
    "#                     pass\n",
    "\n",
    "# print(f'Our model that minimizes MSE on the training data is the SARIMA(4,0,6) x ({final_P},{final_D},{final_Q},{final_S})')\n",
    "# print(f'This model MSE = {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Matt Brem's grid search loop\n",
    "# Starting MSE and (P, D, Q).\n",
    "\n",
    "# mse = 99 * (10 ** 16)\n",
    "# final_P = 0\n",
    "# final_D = 0\n",
    "# final_Q = 0\n",
    "# final_S = 0\n",
    "\n",
    "# for P in range(2):\n",
    "#     for Q in range(2):\n",
    "#         for D in range(2):\n",
    "#             for S in range(0,25,12):\n",
    "#                 try:\n",
    "#                     # Instantiate SARIMA model.\n",
    "#                     sarima = SARIMAX(endog = y_train_hasp],\n",
    "#                                      order = (6, 0, 6),              # (p, d, q)\n",
    "#                                      seasonal_order = (P, D, Q, S),  # (P, D, Q, S)\n",
    "#                                      exog = X_train_sc_hasp) \n",
    "\n",
    "#                     # Fit SARIMA model.\n",
    "#                     model = sarima.fit()\n",
    "\n",
    "#                     # Generate predictions based on training set.\n",
    "#                     preds = model.predict()\n",
    "\n",
    "#                     # Evaluate predictions.\n",
    "#                     print(f'MSE for (6,0,6) x ({P},{D},{Q},{S}) ... {mean_squared_error(train[\"hasp_price_per_mwh\"], preds)}')\n",
    "\n",
    "#                     # Save for final report.\n",
    "#                     if mse > mean_squared_error(train['hasp_price_per_mwh'], preds):\n",
    "#                         mse = mean_squared_error(train['hasp_price_per_mwh'], preds)\n",
    "#                         final_P = P\n",
    "#                         final_D = D\n",
    "#                         final_Q = Q\n",
    "#                         final_S = S\n",
    "\n",
    "#                 except:\n",
    "#                     pass\n",
    "\n",
    "# print(f'Our model that minimizes MSE on the training data is the SARIMA(6,0,6) x ({final_P},{final_D},{final_Q},{final_S})')\n",
    "# print(f'This model MSE = {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and fit the models with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:581: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  warnings.warn('A date index has been provided, but it has no'\n",
      "/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:581: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  warnings.warn('A date index has been provided, but it has no'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =           38     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.75936D+00    |proj g|=  1.35750D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f=  3.74634D+00    |proj g|=  4.73161D-03\n",
      "\n",
      "At iterate   10    f=  3.74449D+00    |proj g|=  1.22084D-02\n",
      "\n",
      "At iterate   15    f=  3.74430D+00    |proj g|=  2.84213D-03\n",
      "\n",
      "At iterate   20    f=  3.74422D+00    |proj g|=  7.80804D-04\n",
      "\n",
      "At iterate   25    f=  3.74412D+00    |proj g|=  4.95879D-03\n",
      "\n",
      "At iterate   30    f=  3.74405D+00    |proj g|=  1.65648D-03\n",
      "\n",
      "At iterate   35    f=  3.74400D+00    |proj g|=  3.07978D-03\n",
      "\n",
      "At iterate   40    f=  3.74392D+00    |proj g|=  1.82710D-03\n",
      "\n",
      "At iterate   45    f=  3.74389D+00    |proj g|=  5.15260D-04\n",
      "\n",
      "At iterate   50    f=  3.74386D+00    |proj g|=  3.76572D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "   38     50     59      1     0     0   3.766D-04   3.744D+00\n",
      "  F =   3.7438600509986610     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for (4,0,6) x (0,1,0,24) ... 105.47\n"
     ]
    }
   ],
   "source": [
    "P = 0\n",
    "D = 1\n",
    "Q = 0\n",
    "S = 24\n",
    "\n",
    "# Instantiate SARIMA model.\n",
    "dam_sarimax01024 = SARIMAX(endog = y_train_dam,\n",
    "                 order = (4, 0, 6),              # (p, d, q)\n",
    "                 seasonal_order = (P, D, Q, S),  # (P, D, Q, S)\n",
    "                 exog = X_train_sc_dam) \n",
    "\n",
    "# Fit SARIMA model.\n",
    "dam_sarimax01024_model = dam_sarimax01024.fit()\n",
    "\n",
    "# Generate predictions based on training set.\n",
    "dam_sarimax01024_preds = dam_sarimax01024_model.predict()\n",
    "\n",
    "# Evaluate predictions.\n",
    "print(f'MSE for (4,0,6) x ({P},{D},{Q},{S}) ... {mean_squared_error(train[\"dam_price_per_mwh\"], dam_sarimax01024_preds):.2f}')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../fitted_models/dam_sarimax01024_model.pkl', 'wb') as f:\n",
    "    pickle.dump(dam_sarimax01024_model, f)\n",
    "    \n",
    "with open('../data/predictions/dam_sarimax01024_preds.pkl', 'wb') as f:\n",
    "    pickle.dump(dam_sarimax01024_preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:581: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  warnings.warn('A date index has been provided, but it has no'\n",
      "/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/statsmodels/tsa/base/tsa_model.py:581: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  warnings.warn('A date index has been provided, but it has no'\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =           40     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.10253D+00    |proj g|=  7.60475D-02\n",
      "\n",
      "At iterate    5    f=  5.09971D+00    |proj g|=  1.84246D-02\n",
      "\n",
      "At iterate   10    f=  5.09389D+00    |proj g|=  6.07601D-02\n",
      "\n",
      "At iterate   15    f=  5.08616D+00    |proj g|=  6.14065D-02\n",
      "\n",
      "At iterate   20    f=  5.08357D+00    |proj g|=  1.82236D-02\n",
      "\n",
      "At iterate   25    f=  5.07888D+00    |proj g|=  1.13175D-01\n",
      "\n",
      "At iterate   30    f=  5.07382D+00    |proj g|=  2.92868D-01\n",
      "\n",
      "At iterate   35    f=  5.07270D+00    |proj g|=  1.65504D-01\n",
      "\n",
      "At iterate   40    f=  5.07177D+00    |proj g|=  3.44070D-01\n",
      "\n",
      "At iterate   45    f=  5.06977D+00    |proj g|=  1.55898D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mehrdadi/opt/anaconda3/lib/python3.8/site-packages/statsmodels/base/model.py:566: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  5.06769D+00    |proj g|=  1.92445D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "   40     50     63      1     0     0   1.924D-01   5.068D+00\n",
      "  F =   5.0676899965518665     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "MSE for (6,0,6) x (0,1,0,24) ... 1490.58\n"
     ]
    }
   ],
   "source": [
    "P = 0\n",
    "D = 1\n",
    "Q = 0\n",
    "S = 24\n",
    "\n",
    "# Instantiate SARIMA model.\n",
    "hasp_sarimax01024 = SARIMAX(endog = y_train_hasp,\n",
    "                 order = (6, 0, 6),              # (p, d, q)\n",
    "                 seasonal_order = (P, D, Q, S),  # (P, D, Q, S)\n",
    "                 exog = X_train_sc_hasp) \n",
    "\n",
    "# Fit SARIMA model.\n",
    "hasp_sarimax01024_model = hasp_sarimax01024.fit()\n",
    "\n",
    "# Generate predictions based on training set.\n",
    "hasp_sarimax01024_preds = hasp_sarimax01024_model.predict()\n",
    "\n",
    "# Evaluate predictions.\n",
    "print(f'MSE for (6,0,6) x ({P},{D},{Q},{S}) ... {mean_squared_error(train[\"hasp_price_per_mwh\"], hasp_sarimax01024_preds):.2f}')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../fitted_models/hasp_sarimax01024_model.pkl', 'wb') as f:\n",
    "    pickle.dump(hasp_sarimax01024_model, f)\n",
    "    \n",
    "with open('../data/predictions/hasp_sarimax01024_preds.pkl', 'wb') as f:\n",
    "    pickle.dump(hasp_sarimax01024_preds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "295px",
    "width": "236px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "226.641px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
